{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f03dc8-5bed-4c91-83f2-5a1cecab8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "운전자의 상태 Good\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "from module.train import test_binary_classification\n",
    "\n",
    "# 모델\n",
    "class driverstatusModel(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32 ,kernel_size=3 , stride=1, padding = 'same' ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64 ,kernel_size=3 , stride=1, padding = 1 ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64,128 ,kernel_size=3 , stride=1, padding = 'same' ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128,64 ,kernel_size=3 , stride=1, padding = 'same' ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64*9*9 , out_features=128 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        out = self.conv1(X)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.classifier(out)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "# 모델불러오기\n",
    "def load_model(load_model_path):\n",
    "    status_model = torch.load(load_model_path ,  map_location=torch.device(\"cpu\"))\n",
    "    status_model = status_model.to(device)\n",
    "\n",
    "    return status_model\n",
    "\n",
    "# Stopwatch : 초시계\n",
    "class Stopwatch:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.elapsed_time = 0\n",
    "        self.running = False\n",
    "\n",
    "    def start(self):\n",
    "        if not self.running:\n",
    "            self.start_time = time.time() - self.elapsed_time\n",
    "            self.running = True\n",
    "\n",
    "    def stop(self):\n",
    "        if self.running:\n",
    "            self.elapsed_time = time.time() - self.start_time\n",
    "            self.running = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.start_time = None\n",
    "        self.elapsed_time = 0\n",
    "        self.running = False\n",
    "\n",
    "    def get_elapsed_time(self):\n",
    "        if self.running:\n",
    "            return time.time() - self.start_time\n",
    "        else:\n",
    "            return self.elapsed_time\n",
    "\n",
    "    def __str__(self):\n",
    "        elapsed = self.get_elapsed_time()\n",
    "        minutes, seconds = divmod(elapsed, 60)\n",
    "        return f\"{int(minutes):02}:{seconds:05.2f}\"\n",
    "\n",
    "# 얼굴을 감지하는 함수 \n",
    "def faceDetect():\n",
    "    stopwatch = Stopwatch()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        cam = cv2.VideoCapture(0)\n",
    "    except:\n",
    "        print(\"camera loading error\")\n",
    "        return\n",
    "    model = YOLO(\"models/yolov8n-pose.pt\")\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"연결 종료\")\n",
    "            break\n",
    "\n",
    "        # 양수: 좌우반전, 0: 상하반전, 음수: 좌우,상하 반전\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Gray scale로 변환함 => 모델이 Grayscale로 학습되어있음\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 모델로 1 프레임을 받아서 모델로 결과값 반환\n",
    "        result = model(frame , show=False , verbose = False , save = False)[0]\n",
    "        try:\n",
    "            keypoints = result.keypoints\n",
    "            # 좌 , 우 눈동자 좌표값\n",
    "            right_eyes = keypoints.xy[0,1]\n",
    "            left_eyes = keypoints.xy[0,2]\n",
    "\n",
    "            # 눈동자 좌표에서 임의로 값을 구해줌\n",
    "            m_right_x = int(right_eyes[0].item()) - 70\n",
    "            m_right_y = int(right_eyes[1].item()) - 70\n",
    "            p_right_x = int(right_eyes[0].item()) + 70\n",
    "            p_right_y = int(right_eyes[1].item()) + 70\n",
    "            \n",
    "            m_left_x = int(left_eyes[0].item()) - 70\n",
    "            m_left_y = int(left_eyes[1].item()) - 70\n",
    "            p_left_x = int(left_eyes[0].item()) + 70\n",
    "            p_left_y = int(left_eyes[1].item()) + 70\n",
    "            \n",
    "            l_eyes = frame_gray[m_left_y:p_left_y , m_left_x:p_left_x]\n",
    "            r_eyes = frame_gray[m_right_y:p_right_y , m_right_x:p_right_x]\n",
    "\n",
    "            # 추론\n",
    "            tf = transforms.Compose([transforms.ToTensor(),transforms.Resize((150,150)),transforms.Normalize([0.5],[0.5])])\n",
    "            l_eyes_value = tf(l_eyes).unsqueeze(dim=0)\n",
    "            l_eyes_value.to('cpu')\n",
    "            r_eyes_value = tf(r_eyes).unsqueeze(dim=0)\n",
    "            r_eyes_value.to('cpu')\n",
    "            status_model.to('cpu')\n",
    "            result_l_eyes = status_model(l_eyes_value)\n",
    "            result_r_eyes = status_model(r_eyes_value)\n",
    "            # print(result_l_eyes , result_r_eyes , frame.shape)\n",
    "            l_eyes_item , r_eyes_item = result_l_eyes.item() , result_r_eyes.item()\n",
    "\n",
    "            # 결과\n",
    "            value = \"Good\" if result_l_eyes.item() >=0.5 and result_r_eyes.item() >=0.5 else \"Sleepy\"\n",
    "\n",
    "            # 화면에 나타낼 값 표시\n",
    "            if value == \"Good\":\n",
    "                cv2.putText(frame, value , (0,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0),3,lineType=cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"{l_eyes_item:0.2f}\", (m_left_x,m_left_y), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0),2,lineType=cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"{r_eyes_item:0.2f}\", (m_right_x,m_right_y), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0),2,lineType=cv2.LINE_AA)\n",
    "                cv2.rectangle(frame, (m_left_x,m_left_y), (p_left_x, p_left_y), (255,0,0), 2)  #사각형 범위\n",
    "                cv2.rectangle(frame, (m_right_x,m_right_y), (p_right_x, p_right_y), (255,0,0), 2)  #사각형 범위\n",
    "                stopwatch.stop()\n",
    "                stopwatch.reset()\n",
    "                \n",
    "            elif value == \"Sleepy\":\n",
    "                stopwatch.start()  # 초시계 시작\n",
    "                elapsed_time_str = str(stopwatch)\n",
    "                elapsed_time = stopwatch.get_elapsed_time() \n",
    "                cv2.putText(frame, elapsed_time_str, (150, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"{l_eyes_item:0.2f}\", (m_left_x,m_left_y), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),2,lineType=cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"{r_eyes_item:0.2f}\", (m_right_x,m_right_y), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),2,lineType=cv2.LINE_AA)\n",
    "                cv2.rectangle(frame, (m_left_x,m_left_y), (p_left_x, p_left_y), (0,0,255), 2)  #사각형 범위\n",
    "                cv2.rectangle(frame, (m_right_x,m_right_y), (p_right_x, p_right_y), (0,0,255), 2)  #사각형 범위\n",
    "                \n",
    "                if  elapsed_time <= 2.0:\n",
    "                    cv2.putText(frame, value , (0,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),2,lineType=cv2.LINE_AA)\n",
    "                else :\n",
    "                    cv2.putText(frame, \"Warning\", (0 , 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "   \n",
    "        except:\n",
    "            continue\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        # cv2.imshow(\"leye\",l_eyes)\n",
    "        # cv2.imshow(\"reye\",r_eyes)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "                break\n",
    "            \n",
    "    cam.release()\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    return value\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(device)\n",
    "    load_model_path = \"models/driverstatusmodels.pth\"\n",
    "    status_model = load_model(load_model_path)\n",
    "    value = faceDetect()\n",
    "    print(f\"운전자의 상태 {value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc754c-c580-47f5-9b8c-67009fdf55c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
